{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Download stopwords\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Import stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Set stopwords for English\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "\n",
    "# Initial Inspection\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"dirty_dataset.csv\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning column names and columns\n",
    "\n",
    "\n",
    "\n",
    "# Define function to normalize characters and remove stopwords\n",
    "def normalize_chars(text):\n",
    "    # Convert to lower case\n",
    "    lower_text = text.lower()\n",
    "    # Remove numbers\n",
    "    no_number_text = re.sub(r'\\d+', '', lower_text)\n",
    "    # Remove all punctuation except words and space\n",
    "    no_punc_text = re.sub(r'[^\\w\\s]', '', no_number_text)\n",
    "    # Remove white spaces\n",
    "    no_wspace_text = no_punc_text.strip()\n",
    "    # Convert string to list of words\n",
    "    lst_text = no_wspace_text.split()\n",
    "    # Remove stopwords\n",
    "    filtered_text = [word for word in lst_text if word not in stop_words]\n",
    "    # Capitalize the first letter of each word\n",
    "    normalized_text = ' '.join([word.capitalize() for word in filtered_text])\n",
    "    return normalized_text\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Normalize Column Names\n",
    "\n",
    "\n",
    "# Apply normalize_chars function to column names\n",
    "df.columns = [normalize_chars(col) for col in df.columns]\n",
    "\n",
    "# Nesting i.e. concatenate the First Name, Middle Name, and Last Name columns\n",
    "df['Name'] = df['First Name'] + ' ' + df['Middle Name'].fillna('') + ' ' + df['Last Name']\n",
    "\n",
    "# Drop the original columns\n",
    "df.drop(columns=['First Name', 'Middle Name', 'Last Name'], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Create a Mapping Dictionary\n",
    "\n",
    "\n",
    "mapping_dict = {\n",
    "    \"Admission Number\": \"admission_number\",\n",
    "    \"Roll Number\": \"roll_number\",\n",
    "    \"Name\": \"name\",\n",
    "    \"Class\": \"class\",\n",
    "    \"Date Birth\": \"date_of_birth\",\n",
    "    \"Age\": \"age\",\n",
    "    \"Fathers Name\": \"father_name\",\n",
    "    \"Mothers Name\": \"mother_name\",\n",
    "    \"Address\": \"address\",\n",
    "    \"Mobile Number\": \"mobile_number\",\n",
    "    \"Weight\": \"weight\",\n",
    "    \"Height\": \"height\",\n",
    "    \"English\": \"english\",\n",
    "    \"Hindi\": \"hindi\",\n",
    "    \"Maths\": \"mathematics\",\n",
    "    \"Science\": \"science\",\n",
    "    \"Social Science\": \"social_science\",\n",
    "    \"Sanskrit\": \"sanskrit\",\n",
    "    \"Total Marks\": \"total_marks\",\n",
    "    \"Percentage\": \"percentage\",\n",
    "    \"Attendance\": \"attendance\",\n",
    "    \"Physical Health\": \"physical_health\",\n",
    "    \"Communication Skills\": \"communication_skills\",\n",
    "    \"Final Grade\": \"final_grade\",\n",
    "    \"Result\": \"result\",\n",
    "    \"Rank\": \"rank\",\n",
    "    \"Remark\": \"remark\"\n",
    "}\n",
    "\n",
    "\n",
    "# Step 3: Apply Standardization\n",
    "\n",
    "\n",
    "# Rename columns using the mapping dictionary\n",
    "df.rename(columns=mapping_dict, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Handle Missing or Duplicate Columns\n",
    "\n",
    "\n",
    "# Iterate over columns and replace missing values in one column with values from the other column\n",
    "for col in df.columns:\n",
    "    if df.columns.duplicated(keep=False)[df.columns.get_loc(col)].any():  # Check if the column is a duplicate\n",
    "        duplicates = df.columns[df.columns == col]  # Get all columns with the same name\n",
    "        for duplicate_col in duplicates:\n",
    "            mask = df[duplicate_col].isna() & ~df[col].isna()  # Mask for missing values in duplicate_col and non-missing values in col\n",
    "            df[duplicate_col] = df[duplicate_col].mask(mask, df[col])  # Replace missing values in duplicate_col with values from col\n",
    "\n",
    "# Remove duplicate columns\n",
    "df = df.loc[:, ~df.columns.duplicated()]\n",
    "\n",
    "\n",
    "# Add missing columns with their standardized names only if they don't already exist\n",
    "for key, value in mapping_dict.items():\n",
    "    if value not in df.columns:\n",
    "        df[value] = None\n",
    "\n",
    "# Remove columns that are not in the mapping dictionary\n",
    "df = df[mapping_dict.values()]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning rows\n",
    "\n",
    "\n",
    "#Step 1: Cleaning 'Admission Number'\n",
    "\n",
    "\n",
    "# Drop duplicates based on 'admission_number'\n",
    "df.drop_duplicates(subset=['admission_number'], inplace=True)\n",
    "\n",
    "# Arrange rows in ascending order of roll_number column\n",
    "df.sort_values(by='admission_number', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Normalize Certain Column Names\n",
    "\n",
    "\n",
    "# Apply normalize_chars function to specific columns\n",
    "df['name'] = df['name'].apply(normalize_chars)\n",
    "df['father_name'] = df['father_name'].apply(normalize_chars)\n",
    "df['mother_name'] = df['mother_name'].apply(normalize_chars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Clean 'roll number' by removing whitespace, special characters and alphabets \n",
    "\n",
    "\n",
    "df['roll_number'] = df['roll_number'].apply(lambda x: re.sub(r'\\s+|[^0-9.]', '', str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4 Standardising and validating class\n",
    "\n",
    "\n",
    "# Point 1: Check for consistency and remove special characters\n",
    "df['class'] = df['class'].str.upper().str.strip()  # Convert to uppercase and remove extra spaces\n",
    "df['class'] = df['class'].apply(lambda x: re.sub(r'[^\\w\\s]', '', x) if pd.notna(x) else x)\n",
    "\n",
    "# Point 2: Convert to categorical\n",
    "df['class'] = pd.Categorical(df['class'])\n",
    "\n",
    "# Point 4: Remove Extra Spaces and standardize format\n",
    "df['class'] = df['class'].str.replace(r'\\s+', ' ', regex=True)  # Replace multiple spaces with single space\n",
    "\n",
    "# Point 5: Validate and standardize entries\n",
    "expected_classes = [f\"V {section}\" for section in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']]\n",
    "df['class'] = df['class'].apply(lambda x: x if x in expected_classes else None)  # Filter out unexpected values\n",
    "\n",
    "# Replace missing sections with the most occurring class\n",
    "most_occuring_class = df[df['class'].notna()]['class'].mode().iloc[0]  # Get the most occurring class excluding missing values\n",
    "df['class'] = df['class'].fillna(most_occuring_class)  # Fill missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 5 Standardising the date format to dd/mm/yyyy\n",
    "\n",
    "\n",
    "def normalise_date(date_str):\n",
    "    # Regular expression pattern to match 'dd/mm/yyyy' format\n",
    "    dd_mm_yyyy_pattern = r'(\\d{1,2})/(\\d{1,2})/(\\d{2,4})'\n",
    "    \n",
    "    # Regular expression pattern to match 'day month year' format\n",
    "    day_month_year_pattern = r'(\\d{1,2})\\s+(\\w+)\\s+(\\d{2,4})'\n",
    "    \n",
    "    # Extracting date, month, and year from the date string for 'dd/mm/yyyy' format\n",
    "    match_dd_mm_yyyy = re.match(dd_mm_yyyy_pattern, date_str)\n",
    "    if match_dd_mm_yyyy:\n",
    "        day, month, year = match_dd_mm_yyyy.groups()\n",
    "        # Pad single-digit day and month with leading zero\n",
    "        day = day.zfill(2)\n",
    "        month = month.zfill(2)\n",
    "        # Rearranging date to the desired format\n",
    "        if len(year) == 2:\n",
    "            year = '20' + year  # Assuming all years are in the 21st century\n",
    "        return f'{day}/{month}/{year}'\n",
    "    \n",
    "    # Extracting date, month, and year from the date string for 'day month year' format\n",
    "    match_day_month_year = re.match(day_month_year_pattern, date_str)\n",
    "    if match_day_month_year:\n",
    "        day, month, year = match_day_month_year.groups()\n",
    "        # Dictionary to map month names to their corresponding numbers\n",
    "        month_mapping = {\n",
    "            'jan': '01', 'feb': '02', 'mar': '03', 'apr': '04', 'may': '05', 'jun': '06',\n",
    "            'jul': '07', 'aug': '08', 'sep': '09', 'oct': '10', 'nov': '11', 'dec': '12'\n",
    "        }\n",
    "        # Normalising month name to its corresponding number\n",
    "        month_num = month_mapping.get(month[:3].lower())\n",
    "        if month_num:\n",
    "            month = month_num.zfill(2)\n",
    "        # Pad single-digit day with leading zero\n",
    "        day = day.zfill(2)\n",
    "        # Rearranging date to the desired format\n",
    "        if len(year) == 2:\n",
    "            year = '20' + year  # Assuming all years are in the 21st century\n",
    "        return f'{day}/{month}/{year}'\n",
    "    \n",
    "    # Return None if the date string does not match any of the expected formats\n",
    "    return None\n",
    "\n",
    "# Apply the function to the 'date of birth' column\n",
    "df['date_of_birth'] = df['date_of_birth'].apply(normalise_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 6 calculate the age based on the date of birth\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "def calculate_age(date_of_birth):\n",
    "    # Convert date_of_birth to a datetime object\n",
    "    dob = datetime.strptime(date_of_birth, '%d/%m/%Y')\n",
    "    \n",
    "    # Get the current date\n",
    "    current_date = datetime.now()\n",
    "    \n",
    "    # Calculate the difference in years\n",
    "    age = current_date.year - dob.year\n",
    "    \n",
    "    # Adjust age if the birthday hasn't occurred yet this year\n",
    "    if current_date.month < dob.month or (current_date.month == dob.month and current_date.day < dob.day):\n",
    "        age -= 1\n",
    "    \n",
    "    return age\n",
    "\n",
    "# Apply the function to the 'date of birth' column\n",
    "df['age'] = df['date_of_birth'].apply(calculate_age)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 7 clean address column by removing multiple whitespaces and unnest it into address and pin_code column\n",
    "\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "# Convert the 'address' column to string type\n",
    "df['address'] = df['address'].astype(str)\n",
    "\n",
    "# Remove multiple spaces in the address column and replace with a single space\n",
    "df['address'] = df['address'].apply(lambda x: re.sub(r'\\s+', ' ', x))\n",
    "df['address'] = df['address'].str.title()\n",
    "\n",
    "# Extract pin code from the address column (including whitespace)\n",
    "df['pin_code'] = df['address'].str.extract(r'(Bhopal)\\s*\\d{6}', expand=False)\n",
    "\n",
    "# Remove everything after \"Bhopal\" from the address column\n",
    "df['address'] = df['address'].str.replace(r'(Bhopal).*$', r'\\1', regex=True)\n",
    "\n",
    "# Read the pin code dataset containing location and pin code\n",
    "pin_code_data = pd.read_csv('pin_code_dataset.csv')\n",
    "\n",
    "\n",
    "# Iterate over each row in the main dataset\n",
    "for index, row in df.iterrows():\n",
    "    if row['pin_code']:\n",
    "        # Extract location from the address before 'Bhopal'\n",
    "        location = row['address'].split('Bhopal')[0].strip()\n",
    "      \n",
    "        # Perform fuzzy matching to find the closest matching location in the pin code dataset\n",
    "        match = process.extractOne(location, pin_code_data['location'])\n",
    "        \n",
    "        # If a match is found and the score is above the threshold, update the pin code in the main dataset\n",
    "        if match[1] >= 80:  # Adjust the threshold as needed\n",
    "            correct_pin_code = pin_code_data.loc[pin_code_data['location'] == match[0], 'pin_code'].values\n",
    "            df.at[index, 'pin_code'] = correct_pin_code[0]\n",
    "\n",
    "# Move pin_code column next to address column\n",
    "address_column_index = df.columns.get_loc('address')\n",
    "df.insert(address_column_index + 1, 'pin_code', df.pop('pin_code'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8 cleaning mobile number by removing non-numeric character, leading zeros, validating it's lenghth and by highlighting duplicates\n",
    "        \n",
    "            \n",
    "# Remove non-numeric characters from mobile numbers\n",
    "df['mobile_number'] = df['mobile_number'].apply(lambda x: ''.join(filter(str.isdigit, str(x))))\n",
    "\n",
    "# Remove all white spaces from mobile numbers\n",
    "df['mobile_number'] = df['mobile_number'].str.replace(' ', '')\n",
    "\n",
    "# Remove leading zeros from mobile numbers\n",
    "df['mobile_number'] = df['mobile_number'].str.lstrip('0')\n",
    "\n",
    "# Ensure mobile numbers are 10 digits long\n",
    "df['mobile_number'] = df['mobile_number'].apply(lambda x: x[-10:] if len(x) > 10 else x)\n",
    "\n",
    "# Identify duplicate mobile numbers with different father names or mother names\n",
    "mask = df.duplicated(subset=['mobile_number'], keep=False) & ~(df.duplicated(subset=['mobile_number', 'father_name'], keep=False) & df.duplicated(subset=['mobile_number', 'mother_name'], keep=False))\n",
    "\n",
    "# Replace duplicate values with None\n",
    "df.loc[mask, 'mobile_number'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 9 cleaning weight, handle missing value using mean, set range, round off, add kg sign \n",
    "\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Remove whitespaces from the weight' column\n",
    "df['weight'] = df['weight'].str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# Clean 'weight' column\n",
    "df['weight'] = df['weight'].str.rstrip('kg')  # Remove 'kg' sign at the end of values\n",
    "df['weight'] = pd.to_numeric(df['weight'], errors='coerce')  # Convert to numeric, coerce errors to NaN\n",
    "\n",
    "# Clip values to range [25, 55]\n",
    "df['weight'] = df['weight'].clip(lower=25, upper=55)\n",
    "\n",
    "# Handle missing values using SimpleImputer with mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "df['weight'] = imputer.fit_transform(df[['weight']])\n",
    "\n",
    "# Round off to whole numbers\n",
    "df['weight'] = df['weight'].round().astype(int)\n",
    "\n",
    "# Add 'kg' sign at the end of values\n",
    "df['weight'] = df['weight'].astype(str) + 'kg'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10 cleaning height, handle missing value using median, set range, round off, add cm sign \n",
    "\n",
    "\n",
    "# Define a function to convert height to cm\n",
    "def convert_height_to_cm(height):\n",
    "    if pd.isna(height) or height == '' or len(height.strip()) == 0:  # Handle missing or empty strings\n",
    "        return np.nan\n",
    "    elif \"'\" in height:  # Convert feet and inches to cm\n",
    "        try:\n",
    "            # Regular expression pattern to match feet and inches format\n",
    "            pattern = r'(\\d+)\\'(\\d+)\\\"'\n",
    "            # Match the pattern in the string\n",
    "            match = re.match(pattern, height)\n",
    "            if match:\n",
    "                feet, inches = map(int, match.groups())\n",
    "                # Convert feet and inches to centimeters\n",
    "                cm = feet * 30.48 + inches * 2.54\n",
    "                return cm\n",
    "            else:\n",
    "                return None  # Return None if the input string does not match the expected format\n",
    "        except ValueError:\n",
    "            return np.nan  # Return NaN for invalid height values\n",
    "    elif 'cm' in height:  # Convert 'cm' to cm\n",
    "        try:\n",
    "            return float(height.strip(' cm'))\n",
    "        except ValueError:\n",
    "            return np.nan  # Return NaN for invalid height values\n",
    "    elif 'm' in height:  # Convert meters to cm\n",
    "        try:\n",
    "            return float(height.strip(' m')) * 100  # Convert to float and multiply by 100\n",
    "        except ValueError:\n",
    "            return np.nan  # Return NaN for invalid height values\n",
    "    elif '.' in height:  # Convert unitless value with decimal to meters\n",
    "        try:\n",
    "            return float(height) * 100  # Convert to float and multiply by 100\n",
    "        except ValueError:\n",
    "            return np.nan  # Return NaN for invalid height values\n",
    "    else:  # Assume unitless value without decimal is in cm\n",
    "        try:\n",
    "            return int(height)  # Convert to integer\n",
    "        except ValueError:\n",
    "            return np.nan  # Return NaN for invalid height values\n",
    "\n",
    "\n",
    "# Remove whitespaces from the 'height' column\n",
    "df['height'] = df['height'].str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "# Clean the 'height' column\n",
    "df['height'] = df['height'].apply(convert_height_to_cm)\n",
    "\n",
    "# Clip values to range [120, 160]\n",
    "df['height'] = df['height'].clip(lower=120, upper=160)\n",
    "\n",
    "# Handle missing values using SimpleImputer with median strategy\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df['height'] = imputer.fit_transform(df[['height']])\n",
    "\n",
    "# Round off to whole numbers\n",
    "df['height'] = df['height'].round().astype(int)\n",
    "\n",
    "# Add 'cm' sign at the end of values\n",
    "df['height'] = df['height'].astype(str) + 'cm'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11 cleaning attendance, handle missing value using mode, set range, round off, add % sign \n",
    "\n",
    "\n",
    "# Remove whitespaces from the 'attendance' column\n",
    "df['attendance'] = df['attendance'].str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    " # Remove '%' sign at the end of values\n",
    "df['attendance'] = df['attendance'].str.rstrip('%')\n",
    "\n",
    "# Convert values to numeric, coerce errors to NaN\n",
    "df['attendance'] = pd.to_numeric(df['attendance'], errors='coerce')\n",
    "\n",
    "# Handle missing values and values greater than 100 using SimpleImputer with mode strategy\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df['attendance'] = imputer.fit_transform(df[['attendance']])\n",
    "\n",
    "# Clip values to range [75, 100]\n",
    "df['attendance'] = df['attendance'].clip(lower=75, upper=100)\n",
    "\n",
    "# Round off to whole numbers\n",
    "df['attendance'] = df['attendance'].round().astype(int)\n",
    "\n",
    "# Add '%' sign again after rounding off\n",
    "df['attendance'] = df['attendance'].astype(str) + '%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13040\\2219601094.py:22: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['physical_health'] = df['physical_health'].fillna(method='bfill')\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13040\\2219601094.py:25: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['communication_skills'] = df['communication_skills'].fillna(method='ffill')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Step 12 cleaning and standardizing physical_health using backward fill and communication_skills using forward fill\n",
    "\n",
    "\n",
    "# Convert all values in the physical_health and communication_skills column to uppercase\n",
    "df['physical_health'] = df['physical_health'].str.upper()\n",
    "df['communication_skills'] = df['communication_skills'].str.upper()\n",
    "\n",
    "# Remove whitespaces from the columns\n",
    "df['physical_health'] = df['physical_health'].str.strip()\n",
    "df['communication_skills'] = df['communication_skills'].str.strip()\n",
    "\n",
    "# Remove special characters and numeric values, retain only alphabetic characters\n",
    "df['physical_health'] = df['physical_health'].str.replace(r'[^a-zA-Z]', '', regex=True)\n",
    "df['communication_skills'] = df['communication_skills'].str.replace(r'[^a-zA-Z]', '', regex=True)\n",
    "\n",
    "# Retain only the first character if it's a valid grade, otherwise consider it as a missing value\n",
    "valid_grades = ['A', 'B', 'C', 'D', 'E']\n",
    "df['physical_health'] = df['physical_health'].apply(lambda x: x[0] if isinstance(x, str) and len(x) == 1 and x in valid_grades else np.nan)\n",
    "df['communication_skills'] = df['communication_skills'].apply(lambda x: x[0] if isinstance(x, str) and len(x) == 1 and x in valid_grades else np.nan)\n",
    "\n",
    "# Handle missing values in 'physical_health' column using backward fill (backfill)\n",
    "df['physical_health'] = df['physical_health'].fillna(method='bfill')\n",
    "\n",
    "# Handle missing values in 'communication_skills' column using forward fill (ffill)\n",
    "df['communication_skills'] = df['communication_skills'].fillna(method='ffill')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13040\\1087995049.py:8: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  dmf = dmf.applymap(lambda x: re.sub(r'\\s+|[^0-9.]', '', str(x)))\n"
     ]
    }
   ],
   "source": [
    "#step 13 cleaning subjects column 'english', 'hindi', 'mathematics', 'science', 'social_science','sanskrit'\n",
    "\n",
    "\n",
    "# Selecting multiple columns and creating a new DataFrame\n",
    "dmf = df[['admission_number','english', 'hindi', 'mathematics', 'science', 'social_science','sanskrit']]\n",
    "\n",
    "# Remove white spaces, special characters, and alphabets from all columns\n",
    "dmf = dmf.applymap(lambda x: re.sub(r'\\s+|[^0-9.]', '', str(x)))\n",
    "\n",
    "# Convert columns to numeric data type\n",
    "dmf=dmf.apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Replace values greater than 100 and less than 33 with NaN using clip except admission_number\n",
    "dmf[['english', 'hindi', 'mathematics', 'science', 'social_science','sanskrit']] = dmf[['english', 'hindi', 'mathematics', 'science', 'social_science','sanskrit']].clip(lower=33, upper=100)\n",
    "\n",
    "# Sort the DataFrame index in ascending order\n",
    "dmf = dmf.sort_index()\n",
    "\n",
    "# Linear interpolation for column 'english'\n",
    "dmf['english'] = dmf['english'].interpolate(method='linear')\n",
    "\n",
    "# Nearest neighbor interpolation for column 'hindi'\n",
    "dmf['hindi'] = dmf['hindi'].interpolate(method='nearest')\n",
    "\n",
    "# Piecewise interpolation for column 'mathematics' (custom implementation)\n",
    "dmf['mathematics'] = dmf['mathematics'].interpolate(method='linear', limit_direction='forward')\n",
    "\n",
    "# Polynomial interpolation for column 'science'\n",
    "df['science'] = df['science'].interpolate(method='polynomial', order=2, limit_direction='both', limit_area='inside')\n",
    "\n",
    "# Spline interpolation for column 'social_science' in the sorted DataFrame\n",
    "dmf['social_science'] = dmf['social_science'].interpolate(method='spline', order=2, limit_direction='both', limit_area='inside')\n",
    "\n",
    "# Multiple imputation for column 'sanskrit'\n",
    "from fancyimpute import IterativeImputer\n",
    "\n",
    "# Create an IterativeImputer object\n",
    "imputer = IterativeImputer(max_iter=10,random_state=0)\n",
    "\n",
    "# Impute missing values in the 'sanskrit' column\n",
    "dmf['sanskrit'] = imputer.fit_transform(dmf[['sanskrit']])\n",
    "\n",
    "# Round off all values in dmf to whole numbers\n",
    "dmf = dmf.round()\n",
    "\n",
    "# Sort by Admission number\n",
    "dmf=dmf.sort_values(by='admission_number', ascending=True)\n",
    "\n",
    "# substitute back to original data frame\n",
    "df[['admission_number','english', 'hindi', 'mathematics', 'science', 'social_science','sanskrit']]=dmf[['admission_number','english', 'hindi', 'mathematics', 'science', 'social_science','sanskrit']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 14 Cleaning 'total_marks', 'percentage', 'final_grade', 'result', 'rank', 'remark'\n",
    "\n",
    "\n",
    "# Remove whitespace and special characters from the specified columns\n",
    "columns_to_clean = ['total_marks', 'percentage', 'final_grade', 'result', 'rank', 'remark']\n",
    "for col in columns_to_clean:\n",
    "    # Convert the column to string type\n",
    "    df[col] = df[col].astype(str)\n",
    "    df[col] = df[col].str.replace(r'\\s+', '', regex=True)  # Remove whitespace\n",
    "    df[col] = df[col].str.replace(r'[^a-zA-Z0-9]+', '', regex=True)  # Remove special characters\n",
    "    \n",
    "    \n",
    "# Remove digits from 'final_grade', 'result', 'remark'\n",
    "df['final_grade'] = df['final_grade'].str.replace(r'\\d+', '')\n",
    "df['result'] = df['result'].str.replace(r'\\d+', '')\n",
    "df['remark'] = df['remark'].str.replace(r'\\d+', '')\n",
    "\n",
    "# Remove alphabets from 'rank', 'total_marks', 'percentage'\n",
    "df['rank'] = df['rank'].str.replace(r'[a-zA-Z]+', '')\n",
    "df['total_marks'] = df['total_marks'].str.replace(r'[a-zA-Z]+', '')\n",
    "df['percentage'] = df['percentage'].str.replace(r'[a-zA-Z]+', '')\n",
    "\n",
    "\n",
    "# Calculate total_marks\n",
    "df['total_marks'] = df[['english', 'hindi', 'mathematics', 'science', 'social_science', 'sanskrit']].sum(axis=1)\n",
    "\n",
    "# Calculate percentage and round off to two decimal places\n",
    "df['percentage'] = (df['total_marks'] / 600) * 100\n",
    "df['percentage'] = df['percentage'].round(2)\n",
    "\n",
    "# Define a function to assign grades based on percentage\n",
    "def assign_grade(percentage):\n",
    "    if percentage >= 90:\n",
    "        return 'A+'\n",
    "    elif 80 <= percentage < 90:\n",
    "        return 'A'\n",
    "    elif 70 <= percentage < 80:\n",
    "        return 'B+'\n",
    "    elif 60 <= percentage < 70:\n",
    "        return 'B'\n",
    "    elif 50 <= percentage < 60:\n",
    "        return 'C+'\n",
    "    elif 40 <= percentage < 50:\n",
    "        return 'C'\n",
    "    elif 33 <= percentage < 40:\n",
    "        return 'D'\n",
    "    else:\n",
    "        return 'E'\n",
    "\n",
    "# Apply the function to create the grade column\n",
    "df['final_grade'] = df['percentage'].apply(assign_grade)\n",
    "\n",
    "\n",
    "# Check if the 'result' column has any missing values or values other than 'Pass'\n",
    "if df['result'].isnull().any() or not all(df['result'] == 'Pass'):\n",
    "    # Replace missing values or values other than 'Pass' with 'Pass'\n",
    "    df.loc[df['result'].isnull() | (df['result'] != 'Pass'), 'result'] = 'Pass'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# First, sort the DataFrame by 'class', 'total_marks', and 'roll_number'\n",
    "df.sort_values(by=['class', 'total_marks', 'roll_number'], ascending=[True, False, True], inplace=True)\n",
    "\n",
    "# Then, use the rank function to assign ranks\n",
    "df['rank'] = df.groupby('class')['total_marks'].rank(method='first', ascending=False)\n",
    "\n",
    "# Convert rank to integer type\n",
    "df['rank'] = df['rank'].astype(int)\n",
    "\n",
    "\n",
    "# Define a dictionary mapping final grades to remarks\n",
    "grade_remarks = {\n",
    "    'A': 'Excellent',\n",
    "    'B': 'Very Good',\n",
    "    'C': 'Good',\n",
    "    'D': 'Satisfactory',\n",
    "    'E': 'Needs Improvement'\n",
    "}\n",
    "\n",
    "# Map final grades to remarks and fill the \"remark\" column\n",
    "df['remark'] = df['final_grade'].map(grade_remarks)\n",
    "\n",
    "# If there are any missing final grades, fill the remark with 'Needs Grading'\n",
    "df['remark'].fillna('Needs Grading', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#step 15 Change datatype to reduce memory \n",
    "\n",
    "\n",
    "# Identify non-numeric columns\n",
    "non_numeric_columns = df.select_dtypes(exclude=[np.number]).columns\n",
    "\n",
    "# Convert non-numeric columns to categorical dtype\n",
    "df[non_numeric_columns] = df[non_numeric_columns].astype('category')\n",
    "\n",
    "# Convert numeric columns (excluding 'admission_number','total_marks','percentage') to int8 dtype\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns.difference([ 'admission_number','total_marks','percentage'])\n",
    "df[numeric_columns] = df[numeric_columns].astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#step 16 Saving the final Dataset\n",
    "\n",
    "\n",
    "df.to_excel('final_dataset.xlsx', index=False)\n",
    "df.to_csv('output.csv', index=False)  # Set index=False to exclude row indices in the output\n",
    "df.to_json('output.json', orient='records')  # orient='records' to output JSON in array format\n",
    "df.to_html('output.html', index=False)  # Set index=False to exclude row indices in the output\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "# Connect to a SQLite database\n",
    "conn = sqlite3.connect('output.db')\n",
    "\n",
    "# Save DataFrame to the database\n",
    "df.to_sql('output_table', conn, if_exists='replace', index=False)  # Set index=False to exclude row indices in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with their corresponding count of empty values:\n",
      "   admission_number roll_number                 name class date_of_birth  age  \\\n",
      "0           2018654          18         Shreya Singh   V A    09/01/2013   11   \n",
      "8            201819                   Beirs Malhotra   V A    24/03/2013   11   \n",
      "5            201863          37   Andy Beirs Khurana   V A    24/11/2013   10   \n",
      "2             20186          43  Faith Hornton Jones   V A    26/07/2013   10   \n",
      "4           2018154          16          Faith Beirs   V A    08/12/2011   12   \n",
      "3            201843          25   Tom Thornton Jones   V A    09/10/2013   10   \n",
      "1            201854          26      Tom Andrews Sen   V B    24/04/2010   14   \n",
      "7            201836          35      Anita Rai Singh   V E    18/05/2012   11   \n",
      "6            201857          38             Andy Pal   V F    14/01/2014   10   \n",
      "\n",
      "           father_name       mother_name  \\\n",
      "0  Pradeep Kumar Singh       Manju Singh   \n",
      "8    Chiraiyu Malhotra    Chalu Malhotra   \n",
      "5              Khurana        Jaya Jones   \n",
      "2          Zahir Jones        Jaya Jones   \n",
      "4          Kabir Beirs   Sofia Rai Beirs   \n",
      "3          Zahir Jones       Kavya Jones   \n",
      "1        Raj Kumar Sen        Meerra Sen   \n",
      "7       Siddhart Singh  Tina Meena Singh   \n",
      "6           Hassan Pal          Maya Pal   \n",
      "\n",
      "                                        address pin_code  ... sanskrit  \\\n",
      "0  852 Karamveer Nagar Near Bhel Om Road Bhopal   462023  ...       91   \n",
      "8              5 Sujalpuram Berasia Road Bhopal   463106  ...       97   \n",
      "5          Raiwada Awadhpuri Anand Nagar Bhopal   462023  ...       33   \n",
      "2      Sonagiri Near Bank Office Piplani Bhopal   462022  ...       95   \n",
      "4     Panchal Puri A-Sector Gandhi Nagar Bhopal   466896  ...       59   \n",
      "3                     11 Number Mp Nagar Bhopal   462026  ...       50   \n",
      "1                   B-Sector Anand Nagar Bhopal   462023  ...       55   \n",
      "7            Doosra Chowraha Arera Hills Bhopal   462011  ...       86   \n",
      "6                   56/8 Ashoka Balampur Bhopal   462010  ...       53   \n",
      "\n",
      "  total_marks percentage  attendance  physical_health  communication_skills  \\\n",
      "0       566.0      94.33         75%                A                     A   \n",
      "8       470.0      78.33         75%                D                     B   \n",
      "5       342.0      57.00         75%                B                     A   \n",
      "2       337.0      56.17         75%                B                     A   \n",
      "4       293.0      48.83         78%                D                     B   \n",
      "3       254.0      42.33         88%                D                     A   \n",
      "1       335.0      55.83         97%                D                     A   \n",
      "7       431.0      71.83         75%                D                     B   \n",
      "6       274.0      45.67         75%                B                     A   \n",
      "\n",
      "   final_grade  result  rank         remark  \n",
      "0           A+    Pass     1  Needs Grading  \n",
      "8           B+    Pass     2  Needs Grading  \n",
      "5           C+    Pass     3  Needs Grading  \n",
      "2           C+    Pass     4  Needs Grading  \n",
      "4            C    Pass     5           Good  \n",
      "3            C    Pass     6           Good  \n",
      "1           C+    Pass     1  Needs Grading  \n",
      "7           B+    Pass     1  Needs Grading  \n",
      "6            C    Pass     1           Good  \n",
      "\n",
      "[9 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count empty values in each column\n",
    "empty_counts = df.isna().sum()\n",
    "\n",
    "# Print columns with their corresponding count of empty values\n",
    "print(\"Columns with their corresponding count of empty values:\")\n",
    "for col, count in empty_counts.items():\n",
    "    if count > 0:\n",
    "        print(f\"{col}: {count} empty values\")\n",
    "        \n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
